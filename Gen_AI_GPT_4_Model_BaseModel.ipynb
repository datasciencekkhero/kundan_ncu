{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IggYrMrvecfS",
    "outputId": "8b926bca-1f8e-43b6-fb56-5faf1d415315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGkenBIgedil"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from Google Drive into a pandas DataFrame\n",
    "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PhD_Thesis_Experiments/GitHub_ToChair/sample_complaints_2years_006_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaAq-tuf-ZiY"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to split hierarchical labels into product and sub-product\n",
    "def split_hierarchical_label(label):\n",
    "    if '::' in label:\n",
    "        return label.split('::')\n",
    "    else:\n",
    "        return [label, 'None'] # Handle cases with no sub-product\n",
    "\n",
    "# Function to calculate hierarchical metrics\n",
    "def hierarchical_metrics(y_true, y_pred):\n",
    "    product_true = [split_hierarchical_label(label)[0] for label in y_true]\n",
    "    sub_product_true = [split_hierarchical_label(label)[1] for label in y_true]\n",
    "    product_pred = [split_hierarchical_label(label)[0] for label in y_pred]\n",
    "    sub_product_pred = [split_hierarchical_label(label)[1] for label in y_pred]\n",
    "\n",
    "    # Calculate metrics at the product level\n",
    "    product_precision = precision_score(product_true, product_pred, average='weighted', zero_division=0)\n",
    "    product_recall = recall_score(product_true, product_pred, average='weighted', zero_division=0)\n",
    "    product_f1 = f1_score(product_true, product_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    # Calculate metrics at the sub-product level (only for non-None sub-products)\n",
    "    # We need to filter for cases where both true and predicted sub-products are not 'None'\n",
    "    valid_sub_product_true = [sub for i, sub in enumerate(sub_product_true) if sub != 'None' and sub_product_pred[i] != 'None']\n",
    "    valid_sub_product_pred = [sub for i, sub in enumerate(sub_product_pred) if sub != 'None' and sub_product_true[i] != 'None']\n",
    "\n",
    "\n",
    "    sub_product_precision = precision_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n",
    "    sub_product_recall = recall_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n",
    "    sub_product_f1 = f1_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n",
    "\n",
    "\n",
    "    # A simple way to combine scores (can be weighted based on importance)\n",
    "    # Here, we'll just average them\n",
    "    hierarchical_precision = (product_precision + sub_product_precision) / 2\n",
    "    hierarchical_recall = (product_recall + sub_product_recall) / 2\n",
    "    hierarchical_f1 = (product_f1 + sub_product_f1) / 2\n",
    "\n",
    "    return {\n",
    "        'product_precision': product_precision,\n",
    "        'product_recall': product_recall,\n",
    "        'product_f1': product_f1,\n",
    "        'sub_product_precision': sub_product_precision,\n",
    "        'sub_product_recall': sub_product_recall,\n",
    "        'sub_product_f1': sub_product_f1,\n",
    "        'hierarchical_precision': hierarchical_precision,\n",
    "        'hierarchical_recall': hierarchical_recall,\n",
    "        'hierarchical_f1': hierarchical_f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nfFCrS6JaSW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOHI3VXGJaPR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import random\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm import tqdm\n",
    "from openai import AsyncAzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNdNYns0QVqR"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 2️⃣ Dataset Setup\n",
    "# ==========================================================\n",
    "# Example: df has ['consumer_complaint_narrative', 'hierarchical_label']\n",
    "# df = pd.read_csv('cfpb_complaints.csv')\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['hierarchical_label'])\n",
    "unique_labels = df['hierarchical_label'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJIzPQdcJZaO"
   },
   "outputs": [],
   "source": [
    "AZURE_API_KEY = \"\"\n",
    "AZURE_ENDPOINT = \"https://datascienceagenticaiwork.cognitiveservices.azure.com/\"\n",
    "API_VERSION = \"2024-12-01-preview\"\n",
    "MODEL_NAME = \"gpt-4.1\"\n",
    "DEPLOYMENT_NAME = \"gpt-4.1\"\n",
    "\n",
    "# -----------------------------\n",
    "# INITIALIZE CLIENT\n",
    "# -----------------------------\n",
    "# Use AsyncAzureOpenAI for asynchronous operations\n",
    "aclient = AsyncAzureOpenAI(\n",
    "    api_key=AZURE_API_KEY,\n",
    "    api_version=API_VERSION,\n",
    "    azure_endpoint=AZURE_ENDPOINT\n",
    ")\n",
    "\n",
    "# --- Set your Azure OpenAI credentials and endpoint ---\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_API_KEY  # <-- Put your key (or store securely)\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_ENDPOINT # <-- Your endpoint\n",
    "\n",
    "# Create the Azure OpenAI client (use the API version supported by your resource)\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version = API_VERSION,\n",
    "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    ")\n",
    "\n",
    "# Use your **deployment name** (not the base model name)\n",
    "# deployment_name = MODEL_NAME  # e.g., \"gpt4o-mini-prod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZqoHxtyJZXe"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 4️⃣ Async GPT-4.1 Zero-Shot Classifier\n",
    "# ==========================================================\n",
    "import asyncio\n",
    "import random\n",
    "\n",
    "async def classify_with_gpt35(session, text, label_list, max_retries=3):\n",
    "    prompt = f\"\"\"\n",
    "    You are a financial complaint classifier.\n",
    "    Given the following consumer complaint, classify it into one of these hierarchical categories:\n",
    "    {', '.join(label_list)}\n",
    "\n",
    "    Complaint:\n",
    "    \"{text}\"\n",
    "\n",
    "    Respond with exactly one label from the list above.\n",
    "    \"\"\"\n",
    "\n",
    "    url = f\"{AZURE_ENDPOINT}openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": AZURE_API_KEY}\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 50\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            async with session.post(url, headers=headers, json=payload, timeout=60) as resp:\n",
    "                if resp.status == 200:\n",
    "                    data = await resp.json()\n",
    "                    return data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "                # Handle 429 (Rate Limit)\n",
    "                elif resp.status == 429:\n",
    "                    await asyncio.sleep(1 + random.random())  # small random delay\n",
    "                    continue  # retry silently\n",
    "\n",
    "                # Handle transient server errors quietly\n",
    "                elif 500 <= resp.status < 600:\n",
    "                    await asyncio.sleep(1 + random.random())\n",
    "                    continue  # retry silently\n",
    "\n",
    "                # For other non-critical errors: skip quietly\n",
    "                else:\n",
    "                    return \"\"\n",
    "\n",
    "        except Exception:\n",
    "            # Suppress exceptions silently, retry\n",
    "            await asyncio.sleep(0.5)\n",
    "            continue\n",
    "\n",
    "    # Return empty label if all retries fail\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj8yH_KzJZUw"
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 5️⃣ Parallel Inference\n",
    "# ==========================================================\n",
    "async def run_parallel_inference(test_data, label_list, max_concurrent=5):\n",
    "    y_true, y_pred = [], []\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "\n",
    "        async def process_row(row):\n",
    "            async with semaphore:\n",
    "                predicted = await classify_with_gpt35(session, row['consumer_complaint_narrative'], label_list)\n",
    "                return row['hierarchical_label'], predicted\n",
    "\n",
    "        for _, row in test_data.iterrows():\n",
    "            tasks.append(process_row(row))\n",
    "\n",
    "        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Classifying\", leave=False):\n",
    "            true_label, pred_label = await f\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(pred_label)\n",
    "\n",
    "    return y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jxeqoxaJZSJ",
    "outputId": "ed88af8d-8d07-4588-ee37-3f61857da21e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 6️⃣ Main Execution\n",
    "# ==========================================================\n",
    "# y_true, y_pred = asyncio.run(run_parallel_inference(test_df, unique_labels, max_concurrent=5))\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()  # allows reusing event loop inside notebook\n",
    "\n",
    "# Run async inference\n",
    "y_true, y_pred = await run_parallel_inference(test_df, unique_labels, max_concurrent=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWufJkqFJZPS",
    "outputId": "0ff8f37c-de4e-424b-faf4-d6a13bb0e9b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Precision: 0.7751\n",
      "Product Recall: 0.5369\n",
      "Product F1: 0.6016\n",
      "Sub Product Precision: 0.6739\n",
      "Sub Product Recall: 0.5061\n",
      "Sub Product F1: 0.5022\n",
      "Hierarchical Precision: 0.7245\n",
      "Hierarchical Recall: 0.5215\n",
      "Hierarchical F1: 0.5519\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 7️⃣ Evaluate Results\n",
    "# ==========================================================\n",
    "metrics = hierarchical_metrics(y_true, y_pred)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUVRXEISFAm-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
