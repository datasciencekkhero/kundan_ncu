{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IggYrMrvecfS","outputId":"d14f842a-e0da-468a-b200-6445a713eb85","executionInfo":{"status":"ok","timestamp":1764614864766,"user_tz":480,"elapsed":16978,"user":{"displayName":"Kundan Karma","userId":"01236420441799182112"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGkenBIgedil"},"outputs":[],"source":["import pandas as pd\n","\n","# Load the dataset from Google Drive into a pandas DataFrame\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PhD_Thesis_Experiments/GitHub_ToChair/FilteredDataSetForExp_002.csv')"]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","import numpy as np\n","\n","# Function to split hierarchical labels into product and sub-product\n","def split_hierarchical_label(label):\n","    if '::' in label:\n","        return label.split('::')\n","    else:\n","        return [label, 'None'] # Handle cases with no sub-product\n","\n","# Function to calculate hierarchical metrics\n","def hierarchical_metrics(y_true, y_pred):\n","    product_true = [split_hierarchical_label(label)[0] for label in y_true]\n","    sub_product_true = [split_hierarchical_label(label)[1] for label in y_true]\n","    product_pred = [split_hierarchical_label(label)[0] for label in y_pred]\n","    sub_product_pred = [split_hierarchical_label(label)[1] for label in y_pred]\n","\n","    # Calculate metrics at the product level\n","    product_precision = precision_score(product_true, product_pred, average='weighted', zero_division=0)\n","    product_recall = recall_score(product_true, product_pred, average='weighted', zero_division=0)\n","    product_f1 = f1_score(product_true, product_pred, average='weighted', zero_division=0)\n","\n","    # Calculate metrics at the sub-product level (only for non-None sub-products)\n","    # We need to filter for cases where both true and predicted sub-products are not 'None'\n","    valid_sub_product_true = [sub for i, sub in enumerate(sub_product_true) if sub != 'None' and sub_product_pred[i] != 'None']\n","    valid_sub_product_pred = [sub for i, sub in enumerate(sub_product_pred) if sub != 'None' and sub_product_true[i] != 'None']\n","\n","\n","    sub_product_precision = precision_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n","    sub_product_recall = recall_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n","    sub_product_f1 = f1_score(valid_sub_product_true, valid_sub_product_pred, average='weighted', zero_division=0) if valid_sub_product_true else 0\n","\n","\n","    # A simple way to combine scores (can be weighted based on importance)\n","    # Here, we'll just average them\n","    hierarchical_precision = (product_precision + sub_product_precision) / 2\n","    hierarchical_recall = (product_recall + sub_product_recall) / 2\n","    hierarchical_f1 = (product_f1 + sub_product_f1) / 2\n","\n","    return {\n","        'product_precision': product_precision,\n","        'product_recall': product_recall,\n","        'product_f1': product_f1,\n","        'sub_product_precision': sub_product_precision,\n","        'sub_product_recall': sub_product_recall,\n","        'sub_product_f1': sub_product_f1,\n","        'hierarchical_precision': hierarchical_precision,\n","        'hierarchical_recall': hierarchical_recall,\n","        'hierarchical_f1': hierarchical_f1\n","    }\n"],"metadata":{"id":"WaAq-tuf-ZiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4nfFCrS6JaSW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","from openai import AzureOpenAI\n","import random\n","import asyncio\n","import aiohttp\n","from tqdm import tqdm\n","from openai import AsyncAzureOpenAI"],"metadata":{"id":"mOHI3VXGJaPR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================================\n","# 2️⃣ Dataset Setup\n","# ==========================================================\n","# Example: df has ['consumer_complaint_narrative', 'hierarchical_label']\n","# df = pd.read_csv('cfpb_complaints.csv')\n","from sklearn.model_selection import train_test_split\n","\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['hierarchical_label'])\n","unique_labels = df['hierarchical_label'].unique().tolist()"],"metadata":{"id":"YNdNYns0QVqR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["AZURE_API_KEY = \"\"\n","AZURE_ENDPOINT = \"\"\n","API_VERSION = \"2024-12-01-preview\"\n","MODEL_NAME = \"gpt-4.1\"\n","DEPLOYMENT_NAME = \"gpt-4.1\"\n","\n","# -----------------------------\n","# INITIALIZE CLIENT\n","# -----------------------------\n","# Use AsyncAzureOpenAI for asynchronous operations\n","aclient = AsyncAzureOpenAI(\n","    api_key=AZURE_API_KEY,\n","    api_version=API_VERSION,\n","    azure_endpoint=AZURE_ENDPOINT\n",")\n","\n","# --- Set your Azure OpenAI credentials and endpoint ---\n","os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_API_KEY  # <-- Put your key (or store securely)\n","os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_ENDPOINT # <-- Your endpoint\n","\n","# Create the Azure OpenAI client (use the API version supported by your resource)\n","client = AzureOpenAI(\n","    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n","    api_version = API_VERSION,\n","    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",")\n","\n","# Use your **deployment name** (not the base model name)\n","# deployment_name = MODEL_NAME  # e.g., \"gpt4o-mini-prod\""],"metadata":{"id":"uJIzPQdcJZaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================================\n","# 4️⃣ Async GPT-4.1 Zero-Shot Classifier\n","# ==========================================================\n","import asyncio\n","import random\n","\n","async def classify_with_gpt35(session, text, label_list, max_retries=3):\n","    prompt = f\"\"\"\n","    You are a financial complaint classifier.\n","    Given the following consumer complaint, classify it into one of these hierarchical categories:\n","    {', '.join(label_list)}\n","\n","    Complaint:\n","    \"{text}\"\n","\n","    Respond with exactly one label from the list above.\n","    \"\"\"\n","\n","    url = f\"{AZURE_ENDPOINT}openai/deployments/{DEPLOYMENT_NAME}/chat/completions?api-version={API_VERSION}\"\n","    headers = {\"Content-Type\": \"application/json\", \"api-key\": AZURE_API_KEY}\n","    payload = {\n","        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n","        \"temperature\": 0.0,\n","        \"max_tokens\": 50\n","    }\n","\n","    for attempt in range(max_retries):\n","        try:\n","            async with session.post(url, headers=headers, json=payload, timeout=60) as resp:\n","                if resp.status == 200:\n","                    data = await resp.json()\n","                    return data[\"choices\"][0][\"message\"][\"content\"].strip()\n","\n","                # Handle 429 (Rate Limit)\n","                elif resp.status == 429:\n","                    await asyncio.sleep(1 + random.random())  # small random delay\n","                    continue  # retry silently\n","\n","                # Handle transient server errors quietly\n","                elif 500 <= resp.status < 600:\n","                    await asyncio.sleep(1 + random.random())\n","                    continue  # retry silently\n","\n","                # For other non-critical errors: skip quietly\n","                else:\n","                    return \"\"\n","\n","        except Exception:\n","            # Suppress exceptions silently, retry\n","            await asyncio.sleep(0.5)\n","            continue\n","\n","    # Return empty label if all retries fail\n","    return \"\"\n"],"metadata":{"id":"SZqoHxtyJZXe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================================\n","# 5️⃣ Parallel Inference\n","# ==========================================================\n","async def run_parallel_inference(test_data, label_list, max_concurrent=5):\n","    y_true, y_pred = [], []\n","    semaphore = asyncio.Semaphore(max_concurrent)\n","\n","    async with aiohttp.ClientSession() as session:\n","        tasks = []\n","\n","        async def process_row(row):\n","            async with semaphore:\n","                predicted = await classify_with_gpt35(session, row['consumer_complaint_narrative'], label_list)\n","                return row['hierarchical_label'], predicted\n","\n","        for _, row in test_data.iterrows():\n","            tasks.append(process_row(row))\n","\n","        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Classifying\", leave=False):\n","            true_label, pred_label = await f\n","            y_true.append(true_label)\n","            y_pred.append(pred_label)\n","\n","    return y_true, y_pred\n"],"metadata":{"id":"xj8yH_KzJZUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==========================================================\n","# 6️⃣ Main Execution\n","# ==========================================================\n","# y_true, y_pred = asyncio.run(run_parallel_inference(test_df, unique_labels, max_concurrent=5))\n","import nest_asyncio\n","import asyncio\n","\n","nest_asyncio.apply()  # allows reusing event loop inside notebook\n","\n","# Run async inference\n","y_true, y_pred = await run_parallel_inference(test_df, unique_labels, max_concurrent=5)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jxeqoxaJZSJ","executionInfo":{"status":"ok","timestamp":1764622526577,"user_tz":480,"elapsed":7652623,"user":{"displayName":"Kundan Karma","userId":"01236420441799182112"}},"outputId":"78600e0c-379b-4d8d-8ccd-5b57caa66ff9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[]}]},{"cell_type":"code","source":["# ==========================================================\n","# 7️⃣ Evaluate Results\n","# ==========================================================\n","metrics = hierarchical_metrics(y_true, y_pred)\n","for key, value in metrics.items():\n","    print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iWufJkqFJZPS","executionInfo":{"status":"ok","timestamp":1764622528649,"user_tz":480,"elapsed":2068,"user":{"displayName":"Kundan Karma","userId":"01236420441799182112"}},"outputId":"e123eba2-8d15-4430-e258-3e11669c9200"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Product Precision: 0.6625\n","Product Recall: 0.5166\n","Product F1: 0.5427\n","Sub Product Precision: 0.5986\n","Sub Product Recall: 0.3570\n","Sub Product F1: 0.3689\n","Hierarchical Precision: 0.6306\n","Hierarchical Recall: 0.4368\n","Hierarchical F1: 0.4558\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DUVRXEISFAm-"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}